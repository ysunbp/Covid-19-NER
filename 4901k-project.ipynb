{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.utils import to_categorical\nimport numpy as np\nimport os\nimport pickle as pkl\n\ntrain_dict = pkl.load(open(\"/kaggle/input/4901k-project-data/train.pkl\", \"rb\"))\nval_dict = pkl.load(open(\"/kaggle/input/4901k-project-data/val.pkl\", \"rb\"))\ntest_dict = pkl.load(open(\"/kaggle/input/4901k-project-data/test.pkl\", \"rb\"))\nprint(\"keys in train_dict:\", train_dict.keys())\nprint(\"keys in val_dict:\", val_dict.keys())\nprint(\"keys in test_dict:\", test_dict.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"index:\", train_dict[\"id\"][0])\nprint(*zip(train_dict[\"word_seq\"][0], train_dict[\"tag_seq\"][0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import chain\nprint(\"count of the NER tags:\", len(set(chain(*train_dict[\"tag_seq\"]))))\nprint(\"all the NER tags:\", set(chain(*train_dict[\"tag_seq\"])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_dict = {'_unk_': 0, '_w_pad_': 1}\n\nfor doc in train_dict['word_seq']:\n    for word in doc:\n        if(word not in vocab_dict):\n            vocab_dict[word] = len(vocab_dict)\n\ntag_dict = {'_t_pad_': 0} # add a padding token\n\nfor tag_seq in train_dict['tag_seq']:\n    for tag in tag_seq:\n        if(tag not in tag_dict):\n            tag_dict[tag] = len(tag_dict)\nword2idx = vocab_dict\nidx2word = {v:k for k,v in word2idx.items()}\ntag2idx = tag_dict\nidx2tag = {v:k for k,v in tag2idx.items()}            \n\nprint(\"size of word vocab:\", len(vocab_dict), \"size of tag_dict:\", len(tag_dict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_sent_length = 128\n\ntrain_tokens = np.array([[word2idx[w] for w in doc] for doc in train_dict['word_seq']])\nval_tokens = np.array([[word2idx.get(w, 0) for w in doc] for doc in val_dict['word_seq']])\ntest_tokens = np.array([[word2idx.get(w, 0) for w in doc] for doc in test_dict['word_seq']])\n\n\ntrain_tags = [[tag2idx[t] for t in t_seq] for t_seq in train_dict['tag_seq']]\ntrain_tags = np.array([to_categorical(t_seq, num_classes=len(tag_dict)) for t_seq in train_tags])\n\nval_tags = [[tag2idx[t] for t in t_seq] for t_seq in val_dict['tag_seq']]\nval_tags = np.array([to_categorical(t_seq, num_classes=len(tag_dict)) for t_seq in val_tags])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"training size:\", train_tokens.shape, \"tag size:\", train_tags.shape)\nprint(\"validating size:\", val_tokens.shape, \"tag size:\", val_tags.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Activation, Embedding, Dropout, BatchNormalization, Input, Add, Concatenate,\\\n    Bidirectional, SimpleRNN, LSTM, GRU, TimeDistributed, SpatialDropout1D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_training_data = train_tokens.shape[0]\nsequence_length = train_tokens.shape[1]\nvocabulary_size = len(vocab_dict)\nnum_tags = train_tags.shape[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training parameters\ndrop = 0.3\nepochs = 40\nbatch_size = 150\nembedding_dim = 20\n\n# lstm parameters\nhidden_size = 30\n\ndef build_RNN(model_type):\n    model = Sequential()\n    model.add(Input(shape=(sequence_length,), dtype='int32'))\n    model.add(Embedding(input_dim=vocabulary_size, \n                        output_dim=embedding_dim, \n                        input_length=sequence_length))\n    model.add(Dropout(drop))\n    if model_type == \"lstm\":\n        model.add(Bidirectional(LSTM(units=hidden_size,return_sequences=True)))\n    elif model_type == \"gru\":\n        model.add(Bidirectional(GRU(units=hidden_size,return_sequences=True)))\n    else:\n        model.add(Bidirectional(SimpleRNN(units=hidden_size,return_sequences=True)))\n    model.add(BatchNormalization())\n    model.add(TimeDistributed(Dense(units=num_tags,\n        activation='softmax')))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm = build_RNN(\"lstm\")\ngru = build_RNN(\"gru\")\n#rnn = build_RNN(\"rnn\")\n\nadam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\nlstm.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"categorical_accuracy\"])\ngru.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"categorical_accuracy\"])\n#rnn.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"categorical_accuracy\"])\n\nprint(lstm.summary)\nprint(gru.summary)\n#print(rnn.summary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Model...\")\nhistory = lstm.fit(\n        train_tokens, \n        train_tags, \n        batch_size=batch_size, \n        epochs=epochs,\n        verbose=1)\nprint(\"Finish!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop = 0.3\nepochs = 15\nbatch_size = 150\nembedding_dim = 60\n\n# lstm parameters\nhidden_size = 120\nsecond_hidden = 120\n\ndef build_rnn(model_type):\n    model = Sequential(name = model_type)\n    model.add(Input(shape=(sequence_length,), dtype='int32'))\n    model.add(Embedding(input_dim=vocabulary_size, \n                        output_dim=embedding_dim, \n                        input_length=sequence_length))\n    model.add(SpatialDropout1D(drop))\n    if model_type == 'double-gru':\n        model.add(Bidirectional(GRU(units=hidden_size,return_sequences=True, recurrent_dropout = 0.1)))\n        model.add(GRU(units=second_hidden, return_sequences = True, recurrent_dropout = 0.1))\n    elif model_type == 'double-lstm':\n        model.add(Bidirectional(LSTM(units=hidden_size,return_sequences=True, recurrent_dropout = 0.1)))\n        model.add(LSTM(units=second_hidden, return_sequences = True, recurrent_dropout = 0.1))\n    elif model_type == 'lstm-gru':\n        model.add(Bidirectional(LSTM(units=hidden_size,return_sequences=True, recurrent_dropout = 0.1)))\n        model.add(GRU(units=second_hidden, return_sequences = True, recurrent_dropout = 0.1))\n    elif model_type == 'gru-lstm':\n        model.add(Bidirectional(GRU(units=hidden_size,return_sequences=True, recurrent_dropout = 0.1)))\n        model.add(LSTM(units=second_hidden, return_sequences = True, recurrent_dropout = 0.1))\n    elif model_type == 'triple-lstm':\n        model.add(Bidirectional(LSTM(units=hidden_size,return_sequences=True, recurrent_dropout = 0.1)))\n        model.add(LSTM(units=second_hidden, return_sequences = True, recurrent_dropout = 0.1))\n        model.add(LSTM(units=second_hidden, return_sequences = True, recurrent_dropout = 0.1))\n    model.add(BatchNormalization())\n    model.add(TimeDistributed(Dense(units=num_tags,\n        activation='softmax')))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"double_lstm = build_rnn('double-lstm')\nadam = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\ndouble_lstm.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"categorical_accuracy\"])\nprint(double_lstm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"double_gru = build_rnn('double-gru')\nadam = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\ndouble_gru.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"categorical_accuracy\"])\nprint(double_gru.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_gru = build_rnn('lstm-gru')\nadam = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999)\nlstm_gru.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"categorical_accuracy\"])\nprint(lstm_gru.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_lstm = build_rnn('gru-lstm')\nadam = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\ngru_lstm.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"categorical_accuracy\"])\nprint(gru_lstm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"triple_lstm = build_rnn('triple-lstm')\ninitial_learning_rate = 0.01\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=300,\n    decay_rate=0.9,\n    staircase=True)\nadam = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999)\ntriple_lstm.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"categorical_accuracy\"])\nprint(triple_lstm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_tags_by_idx = np.argmax(val_tags, axis=2)\nval_labels = np.array([[idx2tag[p] for p in preds] for preds in val_tags_by_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_accuracy(preds, tags, padding_id=\"_t_pad_\"):\n    \"\"\"\n        Input:\n            preds (np.narray): (num_data, length_sentence)\n            tags  (np.narray): (num_data, length_sentence)\n        Output:\n            Proportion of correct prediction. The padding tokens are filtered out.\n    \"\"\"\n    preds_flatten = preds.flatten()\n    tags_flatten = tags.flatten()\n    non_padding_idx = np.where(tags_flatten!=padding_id)[0]\n    \n    return sum(preds_flatten[non_padding_idx]==tags_flatten[non_padding_idx])/len(non_padding_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class valScore(keras.callbacks.Callback):\n    def __init__(self, data):\n        self.x = data\n    def on_epoch_end(self, epoch, logs={}):\n        preds = self.model.predict(self.x, batch_size = 150, verbose = 1)\n        preds_tags_by_idx = np.argmax(preds, axis=2)\n        preds_labels = np.array([[idx2tag[p] for p in pred] for pred in preds_tags_by_idx])\n        c = calc_accuracy(preds_labels, val_labels)\n        print(\"validation accuracy:\", c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_score = valScore(val_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Model...\")\nhistory = double_gru.fit(\n        train_tokens, \n        train_tags, \n        batch_size=batch_size, \n        epochs=epochs,\n        verbose=1, validation_data=(val_tokens,val_tags), callbacks=[val_score])\nprint(\"Finish!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Model...\")\nhistory = double_lstm.fit(\n        train_tokens, \n        train_tags, \n        batch_size=batch_size, \n        epochs=epochs,\n        verbose=1, validation_data=(val_tokens,val_tags),callbacks=[val_score])\nprint(\"Finish!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Model...\")\nhistory = lstm_gru.fit(\n        train_tokens, \n        train_tags, \n        batch_size=batch_size, \n        epochs=epochs,\n        verbose=1, validation_data=(val_tokens,val_tags), callbacks=[val_score])\nprint(\"Finish!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Model...\")\nhistory = gru_lstm.fit(\n        train_tokens, \n        train_tags, \n        batch_size=batch_size, \n        epochs=1,\n        verbose=1, validation_data=(val_tokens,val_tags), callbacks=[val_score])\nprint(\"Finish!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Model...\")\nhistory = triple_lstm.fit(\n        train_tokens, \n        train_tags, \n        batch_size=batch_size, \n        epochs=epochs,\n        verbose=1, validation_data=(val_tokens,val_tags),callbacks=[val_score])\nprint(\"Finish!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"double_gru.save('/kaggle/working/double_gru_better.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"double_lstm.save('/kaggle/working/double_lstm_better.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_gru.save('/kaggle/working/lstm_gru_better.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_lstm.save('/kaggle/working/gru_lstm_better.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"triple_lstm.save('/kaggle/working/triple_lstm_better.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"double_gru = keras.models.load_model('/kaggle/input/4901k-project/double_gru_better.h5')\ndouble_gru.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"double_lstm = keras.models.load_model('/kaggle/input/4901k-project/double_lstm_better.h5')\ndouble_lstm.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_gru = keras.models.load_model('/kaggle/input/4901k-project/lstm_gru_better.h5')\nlstm_gru.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_lstm = keras.models.load_model('/kaggle/input/4901k-project/gru_lstm_better.h5')\ngru_lstm.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"triple_lstm = keras.models.load_model('/kaggle/input/4901k-project/triple_lstm_better.h5')\ntriple_lstm.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds =(double_gru.predict(val_tokens))\npreds_tags_by_idx = np.argmax(preds, axis=2)\npreds_labels = np.array([[idx2tag[p] for p in pred] for pred in preds_tags_by_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=calc_accuracy(preds_labels, val_labels)\nprint('double_gru', c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds =(double_lstm.predict(val_tokens))\npreds_tags_by_idx = np.argmax(preds, axis=2)\npreds_labels = np.array([[idx2tag[p] for p in pred] for pred in preds_tags_by_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = calc_accuracy(preds_labels, val_labels)\nprint('double_lstm', c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds =(lstm_gru.predict(val_tokens))\npreds_tags_by_idx = np.argmax(preds, axis=2)\npreds_labels = np.array([[idx2tag[p] for p in pred] for pred in preds_tags_by_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = calc_accuracy(preds_labels, val_labels)\nprint('lstm_gru', c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds =(gru_lstm.predict(val_tokens))\npreds_tags_by_idx = np.argmax(preds, axis=2)\npreds_labels = np.array([[idx2tag[p] for p in pred] for pred in preds_tags_by_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = calc_accuracy(preds_labels, val_labels)\nprint('gru_lstm', c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds =(triple_lstm.predict(val_tokens))\npreds_tags_by_idx = np.argmax(preds, axis=2)\npreds_labels = np.array([[idx2tag[p] for p in pred] for pred in preds_tags_by_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = calc_accuracy(preds_labels, val_labels)\nprint('triple_lstm', c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append(double_gru)\n#models.append(lstm_gru)\nmodels.append(double_lstm)\nmodels.append(gru_lstm)\nmodels.append(gru_lstm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_input = Input(shape=(sequence_length,))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ensembleModels(models, model_input):\n    yModels=[model(model_input) for model in models] \n    yAvg=keras.layers.average(yModels) \n    modelEns = Model(inputs=model_input, outputs=yAvg, name='ensemble')  \n   \n    return modelEns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ens = ensembleModels(models, model_input)\nens.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds =(ens.predict(val_tokens))\npreds_tags_by_idx = np.argmax(preds, axis=2)\npreds_labels = np.array([[idx2tag[p] for p in pred] for pred in preds_tags_by_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = calc_accuracy(preds_labels, val_labels)\nprint('ensemble', c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds_numerical = ens.predict(test_tokens)\ntest_preds_tags_by_idx = np.argmax(test_preds_numerical, axis=2)\ntest_preds = np.array([[idx2tag[p] for p in preds] for preds in test_preds_tags_by_idx])\nprint(test_preds_numerical.shape)\nprint(test_preds[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport pandas as pd\n\ndf = pd.DataFrame({'id': test_dict[\"id\"],\n                   'labels': [json.dumps(np.array(preds).tolist()) for preds in test_preds]})\ndf.to_csv('./test_preds.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv(\"test_preds.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_preds_numerical = ens.predict(val_tokens)\nval_preds_tags_by_idx = np.argmax(val_preds_numerical, axis=2)\nval_preds = np.array([[idx2tag[p] for p in preds] for preds in val_preds_tags_by_idx])\nprint(val_preds_numerical.shape)\nprint(val_preds[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport pandas as pd\n\ndf = pd.DataFrame({'id': val_dict[\"id\"],\n                   'labels': [json.dumps(np.array(preds).tolist()) for preds in val_preds]})\ndf.to_csv('./val_preds.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(pred_file, ground_file):\n    file_dict = pkl.load(open(ground_file, \"rb\"))\n    file_preds = pd.read_csv(pred_file)\n    return calc_accuracy(np.array([json.loads(line) for line in file_preds[\"labels\"]]), \n              np.array(file_dict[\"tag_seq\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport pandas as pd\n\ndf = pd.DataFrame({'id': val_dict[\"id\"],\n                   'labels': [json.dumps(np.array(preds).tolist()) for preds in val_preds]})\ndf.to_csv('val_preds.csv', index=False)\n\nprint(\"val accuracy\", evaluate('val_preds.csv', \"/kaggle/input/4901k-project-data/val.pkl\"))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}